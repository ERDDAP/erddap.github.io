这一内容基于 [罗伊·门德尔索恩致 ERDDAP 用户组](https://groups.google.com/g/erddap/c/JWoS_y3cygg/m/zCpcNTxNAAAJ) 。 。 。 。

1. 优化 netcdf 文件用于云
———————————————— -

a. 重新包装和页数

最近我做了一些研究 发现了一篇很有趣的文章:

https://nsidc.github.io/cloud-optimized-icesat2/

似乎没有什么能激起热情,比如讨论编程语言,编辑,文件格式,这不是建议什么格式 (编号) 你应该用, 而不是去理解 文件中是什么, 看看可以得到多少改进 ( ERDDAP™ 总是试图对很多这些事情不解, 选择尝试和工作 人们如何实际工作与数据) 。 。 。 。

本文主要针对数据存储于亚马逊S3等对象商店的情况. 使用 http  (编号) 命令,因此与直接连接到 (虚拟) 服务器,由于请求必须进行往返,因此需要更长的时间。 对于对象商店,您希望尽可能少地提出请求,但如果您只是提出真正的大请求以减少呼叫次数,您可能获取的数据比您需要的要多得多,如果不是更多,数据也会同样缓慢。 因此,诀窍是在这两个因素之间实现平衡. 并且虽然对对象商店数据的访问有了很大的改善,但是直接附着的存储也是这样. 在研究这个问题时,一些估计是:

本地磁盘 :
• 支助 搜索时间: 0.1毫米
• 6项申请:0.6ms (可忽略不计) 
• 支助 读取分散的元数据的速度快
云·HTTP(英语:
• 支助 请求延迟:100-200毫米
• 6项请求:600-1200毫米 (非常缓慢&#33;) 
• 支助 每个请求都有网络往返时间

第二点要理解的是netcdf4/hdf5文件被存储成块并返回到页面中,因此当访问对象商店时,每个文件的相对大小会真正影响访问速度,而且默认情况下,文件的元数据会分散到整个文件,因此获得元数据可能会接受多个请求. 论文的要点是,netcdf4/hdf5文件的默认页面大小为4096字节 (4千贝) - 怎么样? (这对云是可怕的&#33;) 由于仅元数据大小可能大于此数,而您的块大小很可能也大于此数。 因此,抽取会需要很多 绕行缓慢。 您想要做的是重新包装文件, 以便所有元数据都位于文件的“ 顶端”, 页面大小至少与元数据大小加一个块大小相同 。 另外,默认情况下,页面大小不是固定的,而是使用不同的策略。 论文发现的是使用固定的页码产生了更好的效果.

那么,我如何确定文件元数据大小?

> h5stat yourfile.nc | grep "File metadata" # metadata size
>

我如何决定块大小:

> h5dump -pH MUR41_file.nc | grep -A3 CHUNKED
>

或

> ncdump -sh MUR41_file.nc | grep ChunkSizes
>

我如何决定页面大小策略:

> h5stat yourfile.nc | grep "File space management strategy"
>

此命令很可能会返回“ H5F_ FSPACE_ SratateGY_ FSM_ AGGR ” , 这是默认策略, 我们希望它返回的是“ H5F_ FSPACE_ SratateGY_ PAGE ” 。

我如何重新包装我的netcdf文件,以便所有的元数据都放在前面,并改变策略,以便使用固定的页面大小,以及使用什么样的页面大小? 我发现的拇指规则是:

页面大小选择 :
• 支助 必须是文件总元数据大小 (关键&#33;) 
• 支助 应该是2的力量 (包括4MB,8MB,16MB等.) 
• 支助 别发疯,32MB是实际最大的
• 支助 考虑块大小 - 页面大小应包含最大块

如上所述,理想的情况是,尺寸应大于元数据大小加一个块的大小。 研究发现,对于许多数据集来说,8MB的页面大小是一个很好的权衡,它可能比元数据大小+块大小要大,并且不会拉得比你需要的更多数据。 为此:

h5repack - S PAGE - G 8388608 您的文件 .nc 优化文件(_T) .nc 

以下是用于获取不同页面大小的值 :

4194304 (英语). (4MB (英语).) 
8388608 (英语). (8MB (英语).) 
16777216 (英语). (16MB (英语).) 
33554432 (英语). (第32MB号) 

(b) 国家 如果在当地也使用文件,是否有好处?

我发现的报纸和其他东西 都表明即使在当地 也有可能从10%到30%的速度提高 在除了详尽无遗的测试中,我发现,当请求与总体文件大小相比相对较小时,速度增速约为10%,而速度增速则随着请求的增大而减少,但我从未发现速度减慢.

c. 调用 泰国

啊,但很多地方有 赶上,这似乎是免费的午餐。 而捕捉到的是固定的页面大小增加了文件的大小. 对于我尝试过的一些案例:

617M 穆尔1 .nc 
632M mur1_优化 .nc 
608M 穆尔2 .nc 
616M mur2_优化 .nc 
29M chla1号 .nc 
40M chla1_优化 .nc 
30M chla2号 .nc 
40M chla2_优化 .nc 

因此,权衡是,文件大小的提高并非微不足道。

(单位:千美元) 但如果我必须重新处理文件...

一个好的问题是,如果我必须写一个脚本来重新处理文件,为什么不只写一个脚本来翻译成像说zarr这样的格式呢? Zarr有很多支持者 如果你对Zarr感兴趣 就做一个快速的Duckuckgo搜索 并且有很多好文章https://www.youtube.com/watch?v=IEAcCmcOdJs  (有趣的是,他提出的许多要点是 冰壶格式试图解决) 。 。 。 因此,为什么你可能不想将文件翻译为像zarr, 首先,如果你定期创建netcdf文件,你可以从现在开始开始优化文件,随着时间的推移,这些文件将看到速度的提高,而你将不必重塑过去的文件, ERDDAP™ 尽管一些内部设置不同,但仍能对文件进行汇总。 其次,你可能有很多工具依赖于netcdf文件,这种方法将意味着不需要重新设定可能包含大量代码的内容. 关键是了解各种选择,选择什么对你的处境最有效。 就像提醒,如果你选择使用 Zarr 文件 ERDDAP™ ,它们必须是zarr格式v2文件.

e. 资源 大数据 - 一个边

大数据被谈论了很多, 但数据有多大是大多数人使用, 如何比较 现代笔记本电脑的能力 (是笔记本电脑,不是服务器) 。 。 。 。 有趣的一幕是:

https://www.youtube.com/watch?v=GELhdezYmP0大约从37分钟开始 虽然整个谈话很有趣

他提到的研究是:

https://motherduck.com/blog/redshift-files-hunt-for-big-data/

因此,确实需要调电的用户比例相对较小,但绝大多数用户可以通过笔记本电脑进行分析,26TB的外部驱动器现在不足300美元,传言到年底将有60TB的外部驱动器. 须思惟之事.

2. 使用 ERDDAP™ 与 Google 云平台或除 AWS 外的其他云供应商
——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

现在 ERDDAP™ 已知只与 AWS 对象商店合作 (第3节) ,尽管改进和概括 ERDDAP™ 对象存储支持在待办事宜列表中 (见https://github.com/ERDDAP/erddap/issues/158) 。 。 。 所以,如果你被告知 你必须运行你的 ERDDAP™ 在谷歌云平台上 (全球气候方案) 还是一个类似的平台? 首先,大多数云平台提供不同的存储级别,通常包括一个类似于本地存储且被操作系统识别的平台,一个通过网络连接的平台通常使用NFS进行访问. (由操作系统直接访问) ,而是一个对象商店。 第一个解决方案是不要使用对象商店,你可以走了。 但是,与往常一样,TANSTAAFL 和这个案子的缺点 就是你从对象商店走出来的 - &gt; NFS 访问 - &gt; 您的本地商店成本也上升 。 (我要补充的是,NFS也通过网络访问,并且有其自身的延迟问题,这也将受益于文件的优化。) 。 。 。 。

如果您需要使用对象存储, 或者只能负担对象存储, 答案是 FUSE 文件系统 (https://github.com/libfuse/libfuse) 。 。 。 在GCP上,这个叫做gcsfuse,安装它的步骤是:

• 在您的 GCP Linux 图像上安装 gcsfuse :
sudo 适切更新
sudo apt 安装 gcsfuse
• 认证全球协商进程 (如果尚未认证) 数字 :
通常通过服务账户或通过运行 gcloud auth 登录来保证您拥有正确的证书 。
• 支助 将 GCS 桶挂载到本地目录 :
使用 gcsfuse 将您的 GCS 桶挂载到本地目录 。 这使得您的 GCP 实例可以访问数据, 好像它是本地文件系统的一部分 。
粘贴您的标签名称/路径/到/挂载/目录

而现在您的对象商店可以访问,就像它属于Linux文件系统的一部分一样,所以将与 ERDDAP™ 。 。 。 这似乎是魔法, 得到最好的两个世界, 一定有一个赶上。 则有. FUSE 文件系统比直接访问对象商店慢得多 (基本上您在访问中增加了另一层) 。 。 。 在我对地图上慢得多的估计中, 我不知道慢多少。 但是,如果你处于必须使用对象商店运行 GCP 的情况,你有一个解决方案,现在可以使用 ERDDAP™ 。 。 。 。

3. 你现在能做的就是帮忙
—————————————————————

如果你有时间和能力测试这些东西 并报告你的结果,那就太好了。 特别是如果您可以访问 GCP 或类似, 并看到多慢 ERDDAP™ 访问使用 FUSE (其实你也可以在AWS测试这个) 。 。 。 如果速度不是太快 那会很棒 因为我有理由相信有些人 很快就会跑掉 ERDDAP™ s与对象存储在GCP上. 因此,这不仅仅是一个理论上感兴趣的问题。
