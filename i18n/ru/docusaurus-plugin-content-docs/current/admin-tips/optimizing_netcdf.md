Этот контент основан на [Послание Роя Мендельсона к ERDDAP Группа пользователей](https://groups.google.com/g/erddap/c/JWoS_y3cygg/m/zCpcNTxNAAAJ) .

1. Оптимизация файлов netcdf для облака
————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

a. переупаковка и размер страницы

Недавно, проводя некоторые исследования, я наткнулся на эту очень интересную статью:

https://nsidc.github.io/cloud-optimized-icesat2/

Ничто, кажется, не разжигает страсти, как обсуждение языков программирования, редакторов и форматов файлов, и это не рекомендация того, какой формат. (s) Вы должны использовать, но, скорее, чтобы понять, что находится в этой статье, и увидеть, сколько улучшений можно получить. ( ERDDAP™ Он всегда пытался быть агностиком по многим из этих вопросов, предпочитая работать с тем, как люди на самом деле работают с данными.) .

Документ в основном направлен на ситуации, когда данные хранятся в хранилище объектов, таком как Amazon S3. Магазины объектов доступны по сети с помощью http  (s) команд, поэтому по сравнению с хранением с прямым подключением к (виртуальный) Сервер, есть гораздо более длительная задержка, так как запрос должен совершить круглую поездку. Для хранения объектов вы хотите сделать как можно меньше запросов, но если вы просто делаете действительно большие запросы, чтобы уменьшить количество звонков, вы можете получить доступ к большему количеству данных, чем вам нужно, что может быть одинаково медленным, если не более. Таким образом, трюк заключается в достижении баланса между этими двумя факторами. И даже несмотря на то, что доступ к данным в хранилищах объектов значительно улучшился, также есть доступ к непосредственно прикрепленному хранилищу. При исследовании этого некоторые оценки:

Локальный диск:
• Время поиска: 0,1 мс
• 6 запросов: 0,6 мс (незначительный) 
• Чтение метаданных быстро
Облачный HTTP:
• Запрос на задержку: 100-200 мс
• 6 запросов: 600-1200 мс (Очень медленно&#33;) 
• Каждый запрос имеет сетевое время туда и обратно.

Второе, что нужно понять, это то, что файлы netcdf4/hdf5 хранятся в кусках и возвращаются на страницах, поэтому относительный размер каждого из них может действительно влиять на скорость доступа, когда доступ осуществляется из хранилища объектов, и что по умолчанию метаданные о файле разбросаны по всему файлу, поэтому получение метаданных может занять несколько запросов. Основной момент статьи заключается в том, что размер страницы по умолчанию для файлов netcdf4/hdf5 составляет 4096 байт. (4KBB) - (Что страшно для облака&#33;) Поскольку только размер метаданных, вероятно, больше, чем это, и более чем вероятно, что ваши размеры кусков также больше, чем это. Таким образом, экстракт потребует много круговых поездок, которые являются медленными. То, что вы хотите сделать, это переупаковать файл так, чтобы все метаданные находились на «верху» файла, и чтобы размер страницы был по крайней мере таким же большим, как размер метаданных плюс размер одного куска. Также по умолчанию размер страницы не фиксируется, а используется стратегия, которая варьируется. То, что обнаружила статья, используя фиксированный размер страницы, дало лучшие результаты.

Как определить размер метаданных файла?

> h5stat yourfile.nc | grep "File metadata" # metadata size
>

Как определить размер куска:

> h5dump -pH MUR41_file.nc | grep -A3 CHUNKED
>

или

> ncdump -sh MUR41_file.nc | grep ChunkSizes
>

Как определить стратегию размера страницы:

> h5stat yourfile.nc | grep "File space management strategy"
>

Скорее всего, эта команда вернет «H5F_FSPACE_STRATEGY_FSM_AGGR», которая является стратегией по умолчанию, и мы хотим, чтобы она вернулась «H5F_FSPACE_STRATEGY_PAGE».

Как я могу переупаковать свой файл netcdf так, чтобы все метаданные были спереди, и изменить стратегию так, чтобы использовался фиксированный размер страницы и какой размер страницы использовать? Правила большого пальца, которые я нашел:

Выбор размера страницы:
• должен быть ≥ общий размер метаданных файла (Критически&#33;) 
• Должна быть мощность 2 (4MB, 8MB, 16MB и т.д.) 
• Не сходите с ума по размеру - 32 МБ обычно является практическим максимумом.
• Рассмотрите размеры кусков - размер страницы должен вмещать самые большие куски

Как было сказано выше, в идеале размер должен быть больше, чем размер метаданных плюс размер одного куска. Исследование показало, что для многих наборов данных размер страницы 8 МБ является хорошим компромиссом, он, вероятно, больше, чем размер метаданных + размер фрагмента, и не тянет больше данных, чем вам нужно. Для достижения этого:

h5repack - S PAGE - G 8388608 yourfile .nc yourfile_optimized (недоступная ссылка) .nc 

Вот значения, которые нужно использовать, чтобы получить разные размеры страниц:

4194304 (4 Мбайт) 
8388608 (8 Мбайт) 
16777216 (16 Мб.) 
33554432 (32 Мбайт) 

Б. Есть ли преимущества при использовании файлов локально?

В статье и других вещах, которые я нашел, предполагается, что даже на местном уровне может быть прирост скорости от 10% до 30%. В своих тестах я обнаружил, что скорость увеличивается примерно на 10%, когда запросы относительно малы по сравнению с общим размером файла, а скорость уменьшается по мере увеличения запроса, но я никогда не находил, что он медленнее.

c. TANSTAAFL

Но где-то есть улов, это похоже на бесплатный обед. И подвох в том, что фиксированный размер страницы увеличивает размер файла. В некоторых случаях я пытался:

617М мур1 .nc 
632M mur1_оптимизированный .nc 
608M mur2 .nc 
616M mur2_оптимизированный .nc 
29М Хла1 .nc 
40M chla1_оптимизированный .nc 
30М Хла2 .nc 
40M chla2_оптимизированный .nc 

Таким образом, компромисс заключается в незначительном увеличении размера файла.

Д. Но если мне все равно придется перерабатывать файлы...

Хороший вопрос: если мне нужно написать сценарий для обработки файлов, почему бы просто не написать сценарий для перевода в такой формат, как «зарр»? У zarr есть много сторонников, и если вы заинтересованы в zarr, просто сделайте быстрый поиск, и есть много хороших сообщений, возможно, более сбалансированный взгляд на zarr.https://www.youtube.com/watch?v=IEAcCmcOdJs  (Интересно, что многие из вопросов, которые он поднимает, это то, что пытается решить формат Айсчунка.) . Так почему же вы не хотите переводить свои файлы на что-то вроде zarr, во-первых, если вы регулярно создаете файлы netcdf, вы можете начать оптимизацию файлов отныне, что со временем приведет к увеличению скорости, и вам не придется переформатировать прошлые файлы. ERDDAP™ Все равно можно будет агрегировать файлы, хотя некоторые внутренние настройки отличаются. Во-вторых, у вас может быть много инструментов, которые зависят от файлов netcdf, и этот подход будет означать отсутствие необходимости переоборудования того, что может быть большим количеством кода. Суть в том, чтобы знать варианты и выбирать то, что лучше всего подходит для вашей ситуации. В качестве напоминания, если вы решите использовать файлы zarr ERDDAP™ Это должны быть файлы формата zarr v2.

Е. Большие данные - в стороне

О больших данных говорят много, но насколько велики данные, которые использует большинство людей, и как это соотносится с возможностями современных ноутбуков. (Ноутбуки, а не серверы) . Интересный факт:

https://www.youtube.com/watch?v=GELhdezYmP0Начните примерно с 37-й минуты, хотя весь разговор интересен.

Исследование, которое он упоминает, находится в:

https://motherduck.com/blog/redshift-files-hunt-for-big-data/

Таким образом, существует относительно небольшой процент пользователей, которым действительно нужно увеличить мощность, но подавляющее большинство пользователей могут делать свои анализы на ноутбуке, внешние диски 26 ТБ теперь стоят менее 300 долларов, и слухи о том, что внешние диски 60 ТБ будут доступны к концу года. Есть над чем подумать.

2. использовать ERDDAP™ Google Cloud Platform и другие облачные провайдеры, кроме AWS
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

На данный момент ERDDAP™ Известно только, что он работает с магазинами объектов AWS. (S3) Хотя улучшение и обобщение ERDDAP™ Поддержка магазина объектов находится в списке Todo (смотретьhttps://github.com/ERDDAP/erddap/issues/158) . Что делать, если вам сказали, что вы должны управлять своим ERDDAP™ Google Cloud Platform (ГКП) Или аналогичная платформа? Во-первых, большинство облачных платформ предлагают различные уровни хранения, обычно в том числе тот, который похож на локальное хранилище и распознается операционной системой, тот, который подключен по сети обычно с использованием NFS для доступа. (Снова доступен напрямую через ОС) И тот, который является объектом хранения. Первое решение - не использовать магазины объектов, и вам было бы хорошо пойти. Но, как всегда, TANSTAAFL и недостатком в этом случае является то, что вы идете из магазина объектов. Доступ к NFS -&gt; Местный магазин ваши расходы также растут. (Я бы добавил, что NFS также доступен по сети и имеет свои проблемы с задержкой, это также выиграет от оптимизации файлов.) .

Если вам нужно использовать хранилище объектов или вы можете позволить себе только хранилище объектов, ответом будет файловая система FUSE. (https://github.com/libfuse/libfuse) . На GCP это называется gcsfuse, и шаги для его установки:

Установите gcsfuse на изображение GCP Linux:
Обновление Sudo Apt
sudo apt установить gcsfuse
• Аутентификация по GCP (Если он уже аутентифицирован) :
Убедитесь, что у вас есть правильные учетные данные, как правило, через учетную запись службы или запустив логин gcloud auth.
• Соберите ведро GCS в локальный каталог:
Добавьте ведро GCS в локальный каталог с помощью gcsfuse. Это позволяет вашему экземпляру GCP получить доступ к данным, как если бы они были частью локальной файловой системы.
gcsfuse your-bucketname /path/to/mount/directory

И теперь к вашему объектному магазину можно получить доступ так, как если бы он был частью файловой системы Linux. ERDDAP™ . Это похоже на волшебство, получая лучшее из обоих миров, должен быть улов. И есть. Файловые системы FUSE работают немного медленнее, чем доступ к хранилище объектов напрямую. (В основном вы добавили еще один слой в доступ.) . В моих исследованиях оценивается, насколько медленнее по всей карте, поэтому я понятия не имею, насколько медленнее. Но если вы находитесь в ситуации, когда вы должны работать на GCP, используя магазины объектов, у вас есть решение, с которым вы можете работать. ERDDAP™ .

3. Что вы можете сделать сейчас, чтобы помочь.
————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

Если у вас есть время и возможность проверить некоторые из этих вещей и сообщить о своих результатах, это было бы здорово. Особенно, если у вас есть доступ к GCP или тому подобное и посмотрите, насколько медленнее. ERDDAP™ Использование FUSE (Вы также можете проверить это на AWS.) . Если штраф за превышение скорости не слишком велик, это было бы замечательно, потому что у меня есть основания полагать, что некоторым людям скоро придется бежать. ERDDAP™ s на GCP с магазином объектов. Это не просто вопрос теоретического интереса.
